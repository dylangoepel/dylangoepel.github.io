<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
   <link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  <link rel="stylesheet" href="/css/franklin.css">
  <link rel="stylesheet" href="/css/basic.css">
  <link rel="icon" href="/assets/favicon.png">
   <title>dylangoepel</title>  
</head>
<body>
  <header>
<div class="blog-name"><a href="/">dylangoepel</a></div>
<nav>
  <ul>
    <li><a href="/">Home</a></li>
  </ul>
  <img src="/assets/hamburger.svg" id="menu-icon">
</nav>
</header>


<!-- Content appended here -->
<div class="franklin-content"><h1 id="defining_the_exponential_function"><a href="#defining_the_exponential_function" class="header-anchor">Defining the exponential function</a></h1>
<h2 id="the_derivatives_of_exponential_functions"><a href="#the_derivatives_of_exponential_functions" class="header-anchor">The derivatives of exponential functions</a></h2>
<p>Let us first consider the function \(f: \mathbb{R} \to \mathbb{R}, x \mapsto a^x\) with \(0 < a \in \mathbb{R}\). For all \(x \in \mathbb{R}\), we have</p>
\[\begin{aligned}
    f'(x) &= \lim_{dx \to 0} \frac{f(x + dx) - f(x)}{dx} \\
    &= \lim_{dx \to 0} \frac{a^{x + dx} - a^x}{dx} \\
    &= a^x \lim_{dx \to 0} \frac{a^{dx} - 1}{dx} \\
    &= a^x \lim_{dx \to 0} \frac{f(dx) - f(0)}{dx} \\
    &= a^x \cdot f'(0).
\end{aligned}\]
<p>We can deduce, that the derivative of an exponential function \(f\) can always represents a scalar multiple \(\mu f\) of \(f\) itself. \(\mu\) is solely dependent on \(f\)&#39;s base \(a\) and can be calculated using the function</p>
\[\begin{aligned}
    \mu : \mathbb{R}^+ &\longrightarrow \mathbb{R} \\
    a &\longmapsto \lim_{x \to 0} \frac{a^x - 1}{x}
\end{aligned}\]
<p>&#40;which we will later identify as the natural logarithm&#41;.</p>
<p>Numerically, it is fairly easy to approximate some values of \(\mu\). Take for example the following Julia code:</p>
<pre><code class="language-julia">mu&#40;a&#41; &#61; &#40;a^&#40;1e-10&#41; - 1&#41; / 1e-10
for i &#61; 1:10
    println&#40;&quot;mu&#40;&#36;i&#41; &#61; &#36;&#40;mu&#40;i&#41;&#41;&quot;&#41;
end</code></pre>
<pre><code class="plaintext code-output">mu(1) = 0.0
mu(2) = 0.6931477614102732
mu(3) = 1.0986123122336267
mu(4) = 1.3862933023744972
mu(5) = 1.6094370280939074
mu(6) = 1.7917600736438999
mu(7) = 1.9459100997210044
mu(8) = 2.0794410637847704
mu(9) = 2.1972246244672533
mu(10) = 2.3025847895041807
</code></pre>
<p>From its definition, it&#39;s easy to see that \(\mu\) must be continuous and monotonically increasing on \(\mathbb{R}\), which implies that there must exist a monotonically increasing and continuous inverse function \(\mu^{-1}: \mathbb{R} \to \mathbb{R}^+\). Specifically, as \(\mu(2) < 1\) and \(\mu(3) > 1\), we can deduce that \(\mu^{-1}(1) \in (2, 3)\). For lack of a better name, we will dub this value \(e\). Thinking back to our definition of \(\mu\), this is equivalent to saying that \((e^x)' = e^x\) for all \(x \in \mathbb{R}\).</p>
<p>Numerically, we can implement a simple bisection algorithm to approximate \(e\):</p>
<pre><code class="language-julia">a &#61; 2
b &#61; 3
ma &#61; mu&#40;a&#41;
mb &#61; mu&#40;b&#41;

for i &#61; 1:100
    v &#61; &#40;a &#43; b&#41; / 2
    mv &#61; mu&#40;v&#41;

    if mv &gt; 1
        global b, mb &#61; v, mv
    elseif mv &lt; 1
        global a, ma &#61; v, mv
    end
end

e &#61; &#40;a &#43; b&#41; / 2
@show e</code></pre>
<pre><code class="plaintext code-output">e = 2.7182790353371393
</code></pre>
<h2 id="getting_to_know_mu_and_mu-1"><a href="#getting_to_know_mu_and_mu-1" class="header-anchor">Getting to know \(\mu\) and \(\mu^{-1}\)</a></h2>
<p>When first encountering the functions \(\mu\), \(\mu^{-1}\), we may want to first spend some time on finding new ways of calculating and approximating them. A first step might be to calculate the derivative \(\mu'\), as this would allow us to not only represent \(\mu\) as an integral &#40;and to approximate it using numeric integration&#41;, but also to compute \(\mu^{-1}\) much more efficiently using the Newton-Raphson algorithm.</p>
<p>For \(a \in \mathbb{R}\), we have</p>
\[\begin{aligned}
    \mu'(a) &= \lim_{dx \to 0} \frac{\mu(a + dx) - \mu(a)}{dx} \\
    &= \lim_{dx \to 0} dx^{-1} \lim_{x \to 0} \frac{(a + dx)^x - a^x}{x} \\
    &= \lim_{x \to 0} x^{-1} \lim_{dx \to 0} \frac{(a + dx)^x - a^x}{dx} \\
    &= \lim_{x \to 0} x^{-1} \frac{d}{da} a^x \\
    &= \lim_{x \to 0} \frac{x a^{x - 1}}{x} \\
    &= a^{-1}
\end{aligned}\]
<p>and by the fundamental theorem of calculus</p>
\[\begin{aligned}
    \mu(a) &= \int_1^{a} \frac{dx}{x}.
\end{aligned}\]
<p>The Newton-Raphson iteration for the equation \(\mu(x) = \lambda\) is</p>
\[\begin{aligned}
    x_{n + 1} &= x_n - \frac{\mu(x_n) - \lambda}{(\mu(x_n) - \lambda)'} \\
    &= x_n - x_n (\mu(x_n) - \lambda) \\
    &= x_n (1 - \mu(x_n) + \lambda)
\end{aligned}\]
<p>Put into code, it looks like this:</p>
<pre><code class="language-julia">function mu_inv&#40;y&#41;
    x &#61; 1
    for i &#61; 1:10
        x &#61; x * &#40;1 - mu&#40;x&#41; &#43; y&#41;
    end
    x
end

@show mu_inv&#40;0&#41;
@show mu_inv&#40;1&#41;
@show mu_inv&#40;2&#41;</code></pre>
<pre><code class="plaintext code-output">mu_inv(0) = 1.0
mu_inv(1) = 2.718279079870738
mu_inv(2) = 7.389057515298066
</code></pre>
<p>Additionally, we are now able to calculate \(\mu^{-1}{'}\) through well-known theorems of calculus:</p>
\[\begin{aligned}
    \mu^{-1}{'}(x) &= \frac{1}{\mu'(\mu^{-1}(x))} \\
    &= \mu^{-1}(x)
\end{aligned}\]
<p>Wait a minute... this looks familiar. We already know a function that satisfies this kind of differential equation. Is it possible that \(\mu^{-1}(x)\) is nothing but \(e^x\)? This is actually very easy to verify:</p>
\[\begin{aligned}
    \mu(e^z) &= \lim_{x \to 0} \frac{(e^z)^x - 1}{x} \\
    &= \lim_{x \to 0} \frac{e^{xz} - 1}{x} \\
    &\stackrel{\text{d'L}}{=} \lim_{x \to 0} \frac{z e^x}{1} \\
    &= z.
\end{aligned}\]
<p>If you know about logarithms, you might want to note that this implies that \(\mu = \ln\).</p>
<p>Putting it all together, we have so far found 4 ways of calculating the exponential function \(e^x\): through bisection of \(\ln\), through the Newton-Raphson algorithm applied to \(\ln\) and simply as an exponential. In addition to that, we can calculate \(\ln(x)\) as a limit, using bisection of \(e^x\), using the Newton-Raphson algorithm applied to \(e^x\) and as a numeric integral.</p>
<p>From a purely mathematical perspective, what we just found out is of even greater significance: We have just calculated the general formula for the derivatives of exponential functions:</p>
\[\begin{aligned}
    (a^x)' = \ln(a) a^x.
\end{aligned}\]
<h2 id="why_would_i_care"><a href="#why_would_i_care" class="header-anchor">Why would I care?</a></h2>
<p>Let&#39;s quickly recap what we did in the last section: We found out that the derivatives of exponential functions of the form \(a^x\) are always just scalar multiples of \(a^x\) and that the multiplication factors are given by the limit \(\lim_{x \to 0} (a^x - 1) x^{-1}\), which we went on to call \(\mu(a)\). Lastly, we proved the existence of a unique number \(e \in \mathbb{R}^+\) with \((e^x)' = e^x\) for all \(x \in \mathbb{R}\) and approximated it as \(e = 2.71828\).</p>
<p>Until now, we have treated the topic of exponential functions as an intellectual game. However, what we found out is insanely useful in just about any scientific field. From a nihilistic mathematician&#39;s point of view, one might go as far as saying that all of science is just a set of differential equations and that the simplest and at the same time most prevalent kind of differential equations can be solved by exponential functions.</p>
<p>Take for example the phenomenon of radioactive decay. Empirically, we can come to the conclusion that the amount of atomic nuclei decaying per second &#40;also called the activity \(A(t)\) of a radioactive substance&#41; is proportional to the amount \(N(t)\) of remaining nuclei in the same substance. This proportionality factor \(\lambda\), also called the decay constant, is specific to the examined element. We can therefore set up the following differential equation:</p>
\[ N'(t) = -A(t) = -\lambda N(t). \]
<p>Equating \(N(t) = N(0) \cdot e^{c x}\), we can very quickly find a solution to this equation:</p>
\[\begin{aligned}
    && c \cdot N(0) \cdot e^{cx} &= -\lambda \cdot N(0) \cdot e^{c x} \\
    &\Leftrightarrow& c &= -\lambda \\
    &\Rightarrow& N(t) &= N(0) e^{-\lambda t}.
\end{aligned}\]
<h2 id="uniqueness"><a href="#uniqueness" class="header-anchor">Uniqueness</a></h2>
<p>We have just seen how exponential functions can be used as solutions to differential equations of the form \(f' = \lambda f\). A natural next question to ask would be whether there are any other functions with the same property. Is \(e^x\) really the only function whose derivative equals the function itself, or is it just the only <em>exponential</em> function with said quality?</p>
<p>Let \(f \in \mathcal{C}^\infty(\mathbb{R}, \mathbb{R})\) be a function with</p>
\[ f(0) = 1 \]
<p>and</p>
\[ f' = f. \]
<p>Trivially, it follows that \(f^{(n)} = f\) for all \(n \in \mathbb{N}\).</p>
<p>Now let \(x \in \mathbb{R}\). Define</p>
\[ I := \begin{cases}
    [0, x], & x_0 \leq 0 \\
    [x, 0], & x_0 < 0
\end{cases} \]
<p>As \(f\) is continuous on \(I\), it is bounded on \(I\). It follows that</p>
\[ \lim_{n \to \infty} \frac{\sup f^{(n)}(I)}{n!} \cdot x^n = 0 \]
<p>which implies that \(Tf(x; 0) = f(x)\) and therefore</p>
\[\begin{aligned}
    f(x) &= \sum_{n = 0}^\infty \frac{f^{(n)}(0)}{n!} x^n \\
    &= \sum_{n = 0}^\infty \frac{f(0)}{n!} x^n \\
    &= \sum_{n = 0}^\infty \frac{x^n}{n!}.
\end{aligned}\]
<p>One can easily verify that this infinite series does in fact represent a solution of our equation, completing our proof of existence and uniqueness.</p>
<p>In particular, we get</p>
\[ e^x = \sum_{n = 0}^\infty \frac{x^n}{n!}. \]
<p>Instead of going from \(e^x\) and reaching our infinite sum representation by taking the Taylor series, we could also have started with the power series and derived the exponential form by first proving the functional equation \(f(a + b) = f(a) f(b)\). For all \(a, b \in \mathbb{R}\), we have</p>
\[\begin{aligned}
    f(a + b) &= \sum_{n = 0}^\infty \frac{(a + b)^n}{n!} \\
    &= \sum_{n = 0}^\infty \frac{1}{n!} \sum_{i = 0}^n \binom{n}{i} a^i b^{n - i} \\
    &= \sum_{n = 0}^\infty \frac{1}{n!} \sum_{i = 0}^n \frac{n!}{i! (n - i)!} a^i b^{n - i} \\\
    &= \sum_{n = 0}^\infty \sum_{i = 0}^n \frac{a^i}{i!} \frac{b^{n - i}}{(n - i)!} \\
    &= \left(\sum_{n = 0}^\infty \frac{a^n}{n!}\right) \cdot \left(\sum_{n = 0}^\infty \frac{b^n}{n!}\right) \\
    &= f(a) \cdot f(b).
\end{aligned}\]
<p>From this equation, we can now inductively follow</p>
\[\begin{aligned}
    f(n a) = f(a)^n
\end{aligned}\]
<p>for \(n \in \mathbb{N}\). As \(f(a) = f(n \frac{a}{n}) = f(\frac{a}{n})^n\) we also get</p>
\[ f(a n^{-1}) = \sqrt[n]{f(a)} \]
<p>and therefore</p>
\[ \forall z \in \mathbb{Q}:\ f(z) = f(1)^z. \]
<p>Let \(r \in \mathbb{R}.\) As \(\mathbb{Q}\) is a dense subset of \(\mathbb{R}\), there exists a sequence \((z_n)_{n \in \mathbb{N}} \subseteq \mathbb{Q}\) with \( \lim_{n \to \infty} z_n = r.\) As \(f\) is continuous, we get</p>
\[ f(r) = \lim_{n \to \infty} f(z_n) = \lim_{n \to \infty} f(1)^{z_n} = f(1)^r. \]
<p>At this point, we would have defined \(e := f(1)\) and conclude \(f(x) = e^x\).</p>
<p>Cheers&#33;</p>
<div class="page-foot">
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Dylan GÃ¶pel.
</div>
</div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>
